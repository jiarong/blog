<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>&lt;3 science</title><link href="http://jiarong.github.io/blog/" rel="alternate"></link><link href="http://jiarong.github.io/blog/feeds/science.atom.xml" rel="self"></link><id>http://jiarong.github.io/blog/</id><updated>2013-07-01T00:00:00-04:00</updated><entry><title>Metagenome Assembly - thoughts on reads mapping back rate</title><link href="http://jiarong.github.io/blog/asseMap.html" rel="alternate"></link><updated>2013-07-01T00:00:00-04:00</updated><author><name>Jiarong Guo</name></author><id>tag:jiarong.github.io/blog,2013-07-01:asseMap.html</id><summary type="html">&lt;p&gt;(with Adina Howe, James Tiedje, Titus Brown)&lt;/p&gt;
&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;This is a follow-up on &lt;a class="reference external" href="http://jiarong.github.io/blog/asseSum.html"&gt;another blog&lt;/a&gt; post on shotgun metagenome assembly of the ARMO (Amazon Rain Forest Microbial Observatory) project. Here I will mainly discuss the problem of low raw reads mapping back rate to the assembled contigs (Table 1).&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Table 1: Assembly statistics. Minimum contig length of 800 bp is chosen. The low mapping percentage is due to the high minimum contig length cutoff.&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="11%" /&gt;
&lt;col width="22%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="8%" /&gt;
&lt;col width="13%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="17%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Sample&lt;/th&gt;
&lt;th class="head"&gt;&amp;gt;800bp contigs&lt;/th&gt;
&lt;th class="head"&gt;total bp&lt;/th&gt;
&lt;th class="head"&gt;max&lt;/th&gt;
&lt;th class="head"&gt;mapping&lt;/th&gt;
&lt;th class="head"&gt;mapping%&lt;/th&gt;
&lt;th class="head"&gt;total reads&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Forest&lt;/td&gt;
&lt;td&gt;265073&lt;/td&gt;
&lt;td&gt;271553890&lt;/td&gt;
&lt;td&gt;9115&lt;/td&gt;
&lt;td&gt;10732078&lt;/td&gt;
&lt;td&gt;0.37%&lt;/td&gt;
&lt;td&gt;2923068636&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Pasture&lt;/td&gt;
&lt;td&gt;497664&lt;/td&gt;
&lt;td&gt;538669724&lt;/td&gt;
&lt;td&gt;24861&lt;/td&gt;
&lt;td&gt;23082813&lt;/td&gt;
&lt;td&gt;0.81%&lt;/td&gt;
&lt;td&gt;2863547487&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are two reasons that I can not use a common explaination (excuse) &amp;quot;bacause it is a metagenome&amp;quot;: 1) &lt;a class="reference external" href="http://ivory.idyll.org/blog/"&gt;Dr.Titus Brown&lt;/a&gt; pointed out the digital normalization output showed the significant genomic saturation (figure 3, 4 in &lt;a class="reference external" href="http://jiarong.github.io/blog/asseSum.html"&gt;this post&lt;/a&gt;). About 25% of the overall data were thrown away by digital normalization, which means they are from genomes with more than 10 fold coverage) and should be assembled. 2) with the same methods (digital normalization and partitioning), &lt;a class="reference external" href="http://adina.github.io/"&gt;Dr. Adina Howe&lt;/a&gt; had acheived the between 10% - 15% raw read mapping back rate on another soil metagenome project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;To track down the problem, I can think of two most probable causes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;contig length cutoff&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mapping tools&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;assembly tools&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="contig-length-cutoff"&gt;
&lt;h3&gt;Contig length cutoff&lt;/h3&gt;
&lt;p&gt;It is obvious that the lower minimum contig length cutoff can give higher raw reads mapping back rate. But here I want to emphasize the relative abundance of the short contigs. Figure 1 shows the majority (&amp;gt;95%) of contigs are less than 1000bp and about 50% of contigs are less than 500bp when 400bp is chosen as minimum. The minimum contig length should be a key parameter to be reported together with raw read mapping rate.
In my data, 800bp minimum cutoff gives 0.37% mapping back rate, while 400bp cutoff gives 2.97%. But the mapping back rate is still low based on the portion of overall reads (25%) thrown away by digital normalization.&lt;/p&gt;
&lt;!-- .. figure:: |filename|/images/F.contigs.400bp.fasta.lenDist.png --&gt;
&lt;div class="figure"&gt;
&lt;img alt="static/images/F.contigs.400bp.fasta.lenDist.png" src="static/images/F.contigs.400bp.fasta.lenDist.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 1: cumulative distribution of contigs based on their lengths. X axis is the length of contigs and Y axis is the number of contigs shorter than a certain length. Contigs have minimum length cutoff of 400bp.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="mapping-methods"&gt;
&lt;h3&gt;Mapping methods&lt;/h3&gt;
&lt;p&gt;I then tested the different mapping methods. The mappers (bwa-aln, bowtie2-e2e, bowtie) requiring the whole read mapped (global alignment) should have lower mapping rate than those (bwa-mem and bowtie2-local) allowing partial match (local alignment), which is confirmed by my testing results (Table 2). Bowtie2-e2e gave higher mapping rate than bowtie due to allowing mismatches. Bwa-aln only allowed a certain number or percentage of mismatch (1% in my case), while bowtie2-e2e took any hit that has higher score than minimum, which is less stringent.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Table 2: Comparison of the different mapping methods. F is all the reads of the forest soil metagenome. Flump is a the biggest partition of that sample. The reads are mapped the contigs with 400bp minimum cutoff.&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="10%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="22%" /&gt;
&lt;col width="27%" /&gt;
&lt;col width="12%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;data&lt;/th&gt;
&lt;th class="head"&gt;bwa-aln&lt;/th&gt;
&lt;th class="head"&gt;bwa-mem&lt;/th&gt;
&lt;th class="head"&gt;bowtie2-e2e&lt;/th&gt;
&lt;th class="head"&gt;bowtie2-local&lt;/th&gt;
&lt;th class="head"&gt;bowtie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Flump&lt;/td&gt;
&lt;td&gt;10.1%&lt;/td&gt;
&lt;td&gt;35.1%&lt;/td&gt;
&lt;td&gt;14.5%&lt;/td&gt;
&lt;td&gt;31.4%&lt;/td&gt;
&lt;td&gt;7.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;2.2%&lt;/td&gt;
&lt;td&gt;8.0%&lt;/td&gt;
&lt;td&gt;3.3%&lt;/td&gt;
&lt;td&gt;6.8%&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="assembly-methods-on-partitions"&gt;
&lt;h3&gt;Assembly methods on partitions&lt;/h3&gt;
&lt;p&gt;After digital normalization and partition, there is no consensus on best way (assembler) to assemble individual partitions. I previously tried a range of Ks and picked the assembly with most assembled basepairs. By merging different assembly from K, I got significantly more contigs (Table 3), which suggests each partition still consists of organisms with different coverage.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Table 3: Assembly statistics of multiple K merging method and best K method applied to individual partitions of the forest soil metagenome.&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="31%" /&gt;
&lt;col width="33%" /&gt;
&lt;col width="24%" /&gt;
&lt;col width="12%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;method&lt;/th&gt;
&lt;th class="head"&gt;&amp;gt;400bp contigs&lt;/th&gt;
&lt;th class="head"&gt;total bp&lt;/th&gt;
&lt;th class="head"&gt;max&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;multiK merged&lt;/td&gt;
&lt;td&gt;13594068&lt;/td&gt;
&lt;td&gt;7722481956&lt;/td&gt;
&lt;td&gt;17000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;bestK&lt;/td&gt;
&lt;td&gt;3916562&lt;/td&gt;
&lt;td&gt;2124266385&lt;/td&gt;
&lt;td&gt;9115&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="improved-reads-mapping-back-rate"&gt;
&lt;h3&gt;Improved reads mapping back rate&lt;/h3&gt;
&lt;p&gt;The multiple K merged assembly with 300bp minimum cutoff had &lt;strong&gt;6.75%&lt;/strong&gt; reads mapped with bwa-aln and &lt;strong&gt;22.80%&lt;/strong&gt; with bwa-mem. The differece of bwa-aln and bwa-mem shows about 17% of reads are partially mapped to the assembly, which indicates the assembly is highly chimeric.&lt;/p&gt;
&lt;p&gt;Now lets go back to the two original two problems:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;25% reads thrown away by the digital normalization process should be from speices with good coverage (&amp;gt; 10).&lt;/p&gt;
&lt;p&gt;The bwa-mem shows 22.80% of reads contributing to the assembly and the number (22.80%) is close to 25%. However, the minimum length chosen here is 300bp. If longer minimum length was chosen, the mapping rate would be very low. Thus there is still room for improvement to get longer contigs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;low mapping back rate compared to the other project (10% -15%).&lt;/p&gt;
&lt;p&gt;First, the metagenome yielding 10% -15% read mapping rate has very similar size to mine, but mine is pooled data from five different location so probably lower coverage. Second, I used bwa-aln instead of bowtie2-e2e. As shown in Table 2, bowtie2-e2e gave higher mapping rate than bwa-aln.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The read mapping back rate is an important parameter for evaluating the quality of metagenome assembly and deciding whether sequencing depth is enough for assembly. Summary of the points learnt:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Minimum length cutoff and read mapping tool can change the mapping rate a lot, so it is important to check these two parameter when comparing the read mapping back rate.&lt;/li&gt;
&lt;li&gt;Unlike single genome assemlby, merging multiple K can improve metagenome assembly a lot.&lt;/li&gt;
&lt;li&gt;The mapping rate difference between bwa-mem and bwa-aln can be an indicator for chimeric level of the assembly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="methods"&gt;
&lt;h2&gt;Methods&lt;/h2&gt;
&lt;p&gt;For assembly tool, velvet (velveth and velvetg) was used with default parameters. Multiple K from 29 to 69 with a step of 4 were chosen except for the largest partition. A step of 10 was used for the largest partition. SGA (fm-merge) is used for merging the assemblies.&lt;/p&gt;
&lt;p&gt;For mapping tools, bwa-aln allowed 0.01 mismatch (bwa aln -n 0.01) and bowtie allow 2 mismatch (bowtie -S -v 2). Bwa-mem (bwa mem), Bowtie2-e2e (bowtie2 --end-to-end) and bowtie2-local (bowtie2 --local) used default parameters.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="bioinformatics"></category><category term="assembly"></category><category term="metagenomics"></category><category term="mapping rate"></category></entry><entry><title>Summary of ARMO shotgun read assembly:</title><link href="http://jiarong.github.io/blog/asseSum.html" rel="alternate"></link><updated>2013-04-22T00:00:00-04:00</updated><author><name>Jiarong Guo</name></author><id>tag:jiarong.github.io/blog,2013-04-22:asseSum.html</id><summary type="html">&lt;p&gt;(with Adina Howe, James Tiedje, Titus Brown)&lt;/p&gt;
&lt;p&gt;I have been working on the assembly of big shotgun metagenomic data from ARMO (Amazon Rain Forest Microbial  Observatory) project. The biggest challenge is the huge data size, 2TB in fastq and more than 6 billions reads after read trimming. One lucky thing is that MSU provides High Performance Computer Clusters, so we have access to memory up to 1TB. Still, to my knowledge, no assemblers can handle this amount of data with 1Tb of memory. Well, some tools like SGA may be able to handle the data if they are very redundant, but this is not the case for soil metagenomic data. &lt;a class="reference external" href="http://arxiv.org/abs/1203.4802"&gt;Digital normalization&lt;/a&gt;
and &lt;a class="reference external" href="http://arxiv.org/abs/1112.4193"&gt;partitioning&lt;/a&gt;, two data preprocessing methods  designed by our lab (&lt;a class="reference external" href="http://ged.msu.edu/"&gt;Dr. Titus Brown&lt;/a&gt;) are used to make the assembly doable.&lt;/p&gt;
&lt;div class="section" id="background-and-data"&gt;
&lt;h2&gt;Background and data&lt;/h2&gt;
&lt;p&gt;Amazon rain forest is very important for global ecosystem and microbial communities play key roles in the nutrient cycling. The goal of this study is  to understand the effect of agriculture practice (conversion of forest to pasture) on microbial community. A survey based on 16s rRNA gene have shown that the land conversion cause higher local microbial diversity but more similar community across space. To further study the microbial community at functional level, shotgun metagenomics is used.&lt;/p&gt;
&lt;p&gt;To evaluate the effects of spatial variation, samples are taken at corner of nested 0.01m, 0.1m, 1m, 10m, 100m square plot at forest site and pasture site. Each sample from a square plot are sequenced by two Illumina HighSeq lanes.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/expDesign.png" src="http://jiarong.github.io/blog/static/images/expDesign.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 1. Experiment design. Samples are collected at corners are nested squares of 0.01, 0.1, 1, 10, 100 meters. Details are in this &lt;a class="reference external" href="http://www.pnas.org/content/110/3/988/F2.expansion.html"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="methods"&gt;
&lt;h2&gt;Methods&lt;/h2&gt;
&lt;p&gt;Data trimming: the end of reads with quality score 2 (ASCII “B”) are trimmed and reads with length longer than 30bp are kept. Pair end reads with overlap are stitched with FLASH (version 1.0.3).&lt;/p&gt;
&lt;p&gt;Digital normalization, sequencing artifact removing, and partitioning: This step is done by a bash script (&lt;a class="reference external" href="https://github.com/jiarong/khmer/blob/master/ged-lab/armo-gjr/asse6.bash"&gt;https://github.com/jiarong/khmer/blob/master/ged-lab/armo-gjr/asse6.bash&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Assembly: VELVET assembler is used to assemble the group of sequence file with kmer size of  33, 37, 39, 49, 69. The one producing the most overall assembly length is picked. Another version of VELVET compiled with “BIGASSEMBLY” flag is used for assembly the biggest group of sequence file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;div class="section" id="computational-cost"&gt;
&lt;h3&gt;Computational cost&lt;/h3&gt;
&lt;p&gt;Digital normalization: 150 cpu hours to finish 10 lanes of Illumina HighSeq data for each treatment (forest or pasture) with 1TB memory.&lt;/p&gt;
&lt;p&gt;Artifact removal: 40 cpu hours to finish 10 lanes.&lt;/p&gt;
&lt;p&gt;Partitioning: 1) 69 cpu hours for loading graph; 2) 346 cpu hours for partitioning graph (12 hours with 32 core on HPC); 3) 12 cpu hours for merging graph; 4) 42 cpu hours for annotating partition; 5) 13 cpu hours for extracting partitions. In total, the partitioning took one week to finish, because the most time consuming step, partitioning graph can be run with multi-threads.&lt;/p&gt;
&lt;p&gt;Assembly: There is always one group file that is significantly larger than the others after partitioning because reads from different species could be connected by some conserved genes or artifacts. We call it the “lump”. The “lump” took about 20 cpu hours, while the other small group files took less than 0.5 cpu hours.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/flowChart.png" src="http://jiarong.github.io/blog/static/images/flowChart.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 2: Flow chart of the assembling process.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="genomic-saturation"&gt;
&lt;h3&gt;Genomic saturation&lt;/h3&gt;
&lt;p&gt;Figure 3, 4 shows there is a fair amount of shared sequence among samples within the same treatment (forest), which also suggests the data within the treatment can be combined for better assemblies.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/FdigiNormByLane.report.png" src="http://jiarong.github.io/blog/static/images/FdigiNormByLane.report.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 3. Genomic content saturation curve from digital normalization output from forest samples. The X axis the number of reads processed by digital normalization. The Y axis the fraction of reads kept after digital normalization in the current sample data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/PdigiNormByLane.report.png" src="http://jiarong.github.io/blog/static/images/PdigiNormByLane.report.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 4. Genomic content saturation curve from digital normalization output from the pasture samples. The X axis the number of reads processed by digital normalization. The Y axis the fraction of reads kept after digital normalization in the current sample data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="assembly-statistics"&gt;
&lt;h3&gt;Assembly statistics&lt;/h3&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Table 1: Assembly statistics. Minimum contig length of 800 bp is chosen. The low mapping percentage is due to the high minimum contig length cutoff.&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="11%" /&gt;
&lt;col width="22%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="8%" /&gt;
&lt;col width="13%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="17%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Sample&lt;/th&gt;
&lt;th class="head"&gt;&amp;gt;800bp contigs&lt;/th&gt;
&lt;th class="head"&gt;total bp&lt;/th&gt;
&lt;th class="head"&gt;max&lt;/th&gt;
&lt;th class="head"&gt;mapping&lt;/th&gt;
&lt;th class="head"&gt;mapping%&lt;/th&gt;
&lt;th class="head"&gt;total reads&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Forest&lt;/td&gt;
&lt;td&gt;265073&lt;/td&gt;
&lt;td&gt;271553890&lt;/td&gt;
&lt;td&gt;9115&lt;/td&gt;
&lt;td&gt;10732078&lt;/td&gt;
&lt;td&gt;0.37%&lt;/td&gt;
&lt;td&gt;2923068636&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Pasture&lt;/td&gt;
&lt;td&gt;497664&lt;/td&gt;
&lt;td&gt;538669724&lt;/td&gt;
&lt;td&gt;24861&lt;/td&gt;
&lt;td&gt;23082813&lt;/td&gt;
&lt;td&gt;0.81%&lt;/td&gt;
&lt;td&gt;2863547487&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As shown in Table 1, pasture data have more and longer contigs assembled (with 800bp cutoff). The DNA content in the two metagenome assemblies share little similarity (Table 2). Rank abundance curves (Figure 5) show the pasture assembly has better coverage than forest assembly.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Table 2 Similarity between two assemblies. Contigs covered is the fraction of total contigs covered by any contigs from the other sample. Total bp covered is the fraction of total basepairs covered by contigs from the other sample.&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="11%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="15%" /&gt;
&lt;col width="25%" /&gt;
&lt;col width="26%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Sample&lt;/th&gt;
&lt;th class="head"&gt;&amp;gt;800bp contigs&lt;/th&gt;
&lt;th class="head"&gt;total bp&lt;/th&gt;
&lt;th class="head"&gt;contigs covered&lt;/th&gt;
&lt;th class="head"&gt;total bp covered&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Forest&lt;/td&gt;
&lt;td&gt;265073&lt;/td&gt;
&lt;td&gt;271553890&lt;/td&gt;
&lt;td&gt;9.30%&lt;/td&gt;
&lt;td&gt;3.50%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Pasture&lt;/td&gt;
&lt;td&gt;497664&lt;/td&gt;
&lt;td&gt;538669724&lt;/td&gt;
&lt;td&gt;5.20%&lt;/td&gt;
&lt;td&gt;1.80%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/FvsP_randAbun.png" src="http://jiarong.github.io/blog/static/images/FvsP_randAbun.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 5. Rank abundance of forest and pasture samples. Bule curve ( F.800.contigCov) is from the combined forest assembly with 800 minimum length and green curve (P.800.contigCov) is from the combined pasture assembly with 800 minimum length. The coverage is based on median of coverages on each base position in contigs after mapping.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="spatial-variation"&gt;
&lt;h3&gt;Spatial variation&lt;/h3&gt;
&lt;p&gt;Clustering and heatmap of samples (Figure 6, 7) in each treatment based on the fold coverage of top 1000 most abundant contig shows that even though sharing a fair amount of genomic content, there are still spatial  variation between samples. The closer the distance, the more similar the samples are.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/F.1500bp.cov.table.dendrogram.hellinger.png" src="http://jiarong.github.io/blog/static/images/F.1500bp.cov.table.dendrogram.hellinger.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 6. Heatmap of top 1000 most abundant contigs within forest samples. Samples are in the rows. “F” stands for forest. The number follow the “F” stands for the distance of sampling spot. For example, “F001” is 0.01m at forest. Contigs are the columns (name not shown due to large amount). The columns are sorted based on the abundance in F01 for A. The abundance matrix is transformed by hellinger transform prior to clustering.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="|filename|/images/P.1500bp.cov.table.dendrogram.hellinger.png" src="http://jiarong.github.io/blog/static/images/P.1500bp.cov.table.dendrogram.hellinger.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Figure 7. Heatmap of top 1000 most abundant contigs within pasture samples. Samples are in the rows. “P” stands for pasture. The number follow the “P” stands for the distance of sampling spot. For example, “P001” is 0.01m at pasture. Contigs are the columns (name not shown due to large amount). The columns are sorted based on the abundance in P01 for pasture. The abundance matrix is transformed by hellinger transform prior to clustering.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Digital normalization and partitioning are effective methods to assemble large metagenomic data. The assemblies from combined forest samples and from combined pasture samples share less than 5% similarity, which indicates the metagenomic content in forest and pasture are quite different. The microbial communities across space share a fair amount of genomic content, but they are still distinct from each other, especially when distance are large. The assembly data has been uploaded to MG-RAST for annotation. Next step will be comparing the communities with gene or functional category rather than just the contigs.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="bioinformatics"></category><category term="assembly"></category><category term="metagenomics"></category></entry></feed>